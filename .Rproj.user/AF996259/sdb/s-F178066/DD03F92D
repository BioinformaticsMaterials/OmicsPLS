{
    "contents" : "#' O2PLS: Two-Way Orthogonal Partial Least Squares\n#' \n#' This is based on work of (Trygg, Wold, 2003). \n#' Includes the O2PLS fit, some misc functions and some cross-validation tools.\n#' @author \n#' Said el Bouhaddani (\\email{s.el_bouhaddani@@lumc.nl}), \n#' Jeanine Houwing-Duistermaat (\\email{J.J.Houwing@@lumc.nl}), \n#' Geurt Jongbloed (\\email{G.Jongbloed@@tudelft.nl}), \n#' Hae-Won Uh (\\email{H.Uh@@lumc.nl}).\n#' \n#' Maintainer: Said el Bouhaddani (\\email{s.el_bouhaddani@@lumc.nl}).\n#' \n#' @section Functions:\n#' The O2PLS fit is done with \\code{\\link{o2m}}. Cross-validation is done with \\code{\\link{loocv}} or \\code{\\link{adjR2}} which may depend on the \\code{parallel} package.\n#' \n#' List of all functions:\\itemize{\n#' \\item{\\code{\\link{adjR2}}}\n#' \\item{\\code{\\link{loocv}}}\n#' \\item{\\code{\\link{loocv_combi}}}\n#' \\item{\\code{\\link{mse}}}\n#' \\item{\\code{\\link{orth}}}\n#' \\item{\\code{\\link{o2m}}}\n#' \\item{\\code{\\link{o2m_stripped}}}\n#' \\item{\\code{\\link{rmsep}}}\n#' \\item{\\code{\\link{rmsep_combi}}}\n#' \\item{\\code{\\link{ssq}}}\n#' \\item{\\code{\\link{summary_o2m}}}\n#' \\item{\\code{\\link{vnorm}}}\n#' }\n#' \n#' @docType package\n#' @name O2PLS\n#' @keywords O2PLS\n#' @import parallel\nNULL\n\n#' Orthogonalize a matrix\n#' \n#' @param X Numeric vector or matrix.\n#' @return An orthogonalized representation of \\code{X}\n#' @details The definition of orthogonalizing a matrix is not ambiguous. Here \\code{X} is represented by all eigenvectors. The eigenvalues are set to 1.\n#' An alternative, not implemented, way is to orthonormalize the second columns of \\code{X} w.r.t. the first column, and the third column w.r.t. the first two columns etc.\n#' @examples\n#' orth(c(3,4))\n#' orth(matrix(rnorm(500),100,5))\n#' @export\north<-function(X)\n{\n  e=svd(X)\n  return(tcrossprod(e$u,e$v))\n}\n\n#' Calculate Sum of Squares\n#' \n#' @param X Numeric vector or matrix.\n#' @return The sum of squared elements of \\code{X}\n#' @details This is the Frobenius norm of \\eqn{X}.\n#' @examples\n#' ssq(1:5)\n#' ssq(rnorm(1e5))/1e5\n#' @export\nssq<-function(X)\n{\n  return(sum(X^2))\n}\n\n#' Calculate mean squared difference\n#' \n#' @param x Numeric vector or matrix.\n#' @param y Numeric vector or matrix.\n#' @return The mean of the squared differences elementwise.\n#' @details Is equal to ssq(x-y)/length(c(x)). If \\code{x} and \\code{y} are of unequal length, the invoked minus-operator will try to make the best out of it (with a probability on a warning). \n#' In particular if \\code{x} is an N x p matrix and \\code{y} an N x 1 vector, y is subtracted from each column of \\code{x}.\n#' @examples \n#' mse(2,0)\n#' mse(1:10,2:11) == 1\n#' mse(matrix(rnorm(500),100,5),matrix(rnorm(500),100,5))\n#' @export\nmse <- function(x,y)\n  #Input: 2 matrices x,y\n  #Output: mean squared distance between 2 matrices (number)\n{\n  if(length(x)!=length(y)){warning(\"unequal length:result may not be sensible\")}\n  mean((x-y)^2)\n}\n\n#' Perform O2-PLS with two-way orthogonal corrections\n#' \n#' NOTE THAT THIS FUNCTION DOES NOT CENTER NOR SCALES THE MATRICES! Any normalization you will have to do yourself. It is best practice to at least center the variables though.\n#' \n#' @param X Numeric matrix. Other types will be coerced to matrix with \\code{as.matrix} (if this is possible)\n#' @param Y Numeric matrix. Other types will be coerced to matrix with \\code{as.matrix} (if this is possible)\n#' @param n Integer. Number of joint PLS components. Must be positive!\n#' @param nx Integer. Number of orthogonal components in \\eqn{X}. Negative values are interpreted as 0\n#' @param ny Integer. Number of orthogonal components in \\eqn{Y}. Negative values are interpreted as 0\n#' \n#' @return A list containing\n#'    \\item{Tt}{Joint \\eqn{X} scores}\n#'    \\item{W.}{Joint \\eqn{X} loadings}\n#'    \\item{U}{Joint \\eqn{Y} scores}\n#'    \\item{C.}{Joint \\eqn{Y} loadings}\n#'    \\item{E}{Residuals in \\eqn{X}}\n#'    \\item{Ff}{Residuals in \\eqn{Y}}\n#'    \\item{T_Yosc}{Orthogonal \\eqn{X} scores}\n#'    \\item{P_Yosc.}{Orthogonal \\eqn{X} loadings}\n#'    \\item{W_Yosc}{Orthogonal \\eqn{X} weights}\n#'    \\item{U_Xosc}{Orthogonal \\eqn{Y} scores}\n#'    \\item{P_Xosc.}{Orthogonal \\eqn{Y} loadings}\n#'    \\item{C_Xosc}{Orthogonal \\eqn{Y} weights}\n#'    \\item{B_U}{Regression coefficient in \\code{Tt} ~ \\code{U}}\n#'    \\item{B_T.}{Regression coefficient in \\code{U} ~ \\code{Tt}}\n#'    \\item{H_TU}{Residuals in \\code{Tt} in \\code{Tt} ~ \\code{U}}\n#'    \\item{H_UT}{Residuals in \\code{U} in \\code{U} ~ \\code{Tt}}\n#'    \\item{X_hat}{Prediction of \\eqn{X} with \\eqn{Y}}\n#'    \\item{Y_hat}{Prediction of \\eqn{Y} with \\eqn{X}}\n#'    \\item{R2X}{Variation (measured with \\code{\\link{ssq}}) of the modeled part in \\eqn{X} (defined by joint + orthogonal variation) as proportion of variation in \\eqn{X}}\n#'    \\item{R2Y}{Variation (measured with \\code{\\link{ssq}}) of the modeled part in \\eqn{Y} (defined by joint + orthogonal variation) as proportion of variation in \\eqn{Y}}\n#'    \\item{R2Xcorr}{Variation (measured with \\code{\\link{ssq}}) of the joint part in \\eqn{X} as proportion of variation in \\eqn{X}}\n#'    \\item{R2Ycorr}{Variation (measured with \\code{\\link{ssq}}) of the joint part in \\eqn{Y} as proportion of variation in \\eqn{Y}}\n#'    \\item{R2X_YO}{Variation (measured with \\code{\\link{ssq}}) of the orthogonal part in \\eqn{X} as proportion of variation in \\eqn{X}}\n#'    \\item{R2Y_XO}{Variation (measured with \\code{\\link{ssq}}) of the orthogonal part in \\eqn{Y} as proportion of variation in \\eqn{Y}}\n#'    \\item{R2Xhat}{Variation (measured with \\code{\\link{ssq}}) of the predicted \\eqn{X} as proportion of variation in \\eqn{X}}\n#'    \\item{R2Yhat}{Variation (measured with \\code{\\link{ssq}}) of the predicted \\eqn{Y} as proportion of variation in \\eqn{Y}}\n#'    \n#'    @details If both \\code{nx} and \\code{ny} are zero, \\code{o2m} is equivalent to PLS2 with orthonormal loadings.\n#'    This is a `slower' implementation of O2PLS, using \\code{\\link{svd}}. For cross-validation purposes, consider using \\code{\\link{o2m_stripped}}.\n#'    \n#'    @seealso \\code{\\link{ssq}}, \\code{\\link{summary_o2m}}, \\code{\\link{o2m_stripped}}\n#' @export\no2m<-function(X,Y,n,nx,ny)\n{\n  X = as.matrix(X)\n  Y = as.matrix(Y)\n  if(n<=0){stop(\"#joint components must be >0\")}\n  X_true = X\n  Y_true = Y\n  \n  T_Yosc = U_Xosc = matrix(0,length(X[,1]),1)\n  P_Yosc = W_Yosc = matrix(0,length(X[1,]),1)\n  P_Xosc = C_Xosc = matrix(0,length(Y[1,]),1)\n  \n  N=dim(X)[1]\n  p=dim(X)[2]; q=dim(Y)[2]\n  \n  if(nx*ny>0){\n    # larger principal subspace\n    n2=n+max(nx,ny)\n    \n    cdw = svd(t(Y)%*%X,nu=n2,nv=n2); \n    C=cdw$u;W=cdw$v\n    \n    Tt = X%*%W;                    \n    \n    if(nx > 0){\n      # Orthogonal components in Y\n      E_XY = X - Tt%*%t(W);\n      \n      udv = svd(t(E_XY)%*%Tt,nu=nx,nv=0);\n      W_Yosc = udv$u ; s = udv$d \n      T_Yosc = X%*%W_Yosc;\n      P_Yosc = t(solve(t(T_Yosc)%*%T_Yosc)%*%t(T_Yosc)%*%X);\n      X = X - T_Yosc%*%t(P_Yosc);\n      \n      # Update T again\n      Tt = X%*%W;\n    }\n    \n    U = Y%*%C;                   # 3.2.1. 4\n    \n    if(ny > 0){\n      # Orthogonal components in Y\n      F_XY = Y - U%*%t(C);\n      \n      udv = svd(t(F_XY)%*%U,nu=ny,nv=0);\n      C_Xosc = udv$u ; s = udv$d \n      U_Xosc = Y%*%C_Xosc;\n      P_Xosc = t(solve(t(U_Xosc)%*%U_Xosc)%*%t(U_Xosc)%*%Y);\n      Y = Y - U_Xosc%*%t(P_Xosc);\n      \n      # Update U again\n      U = Y%*%C;\n    }\n  }\n  # Re-estimate joint part in n-dimensional subspace\n  cdw = svd(t(Y)%*%X,nu=n,nv=n);    # 3.2.1. 1\n  C=cdw$u;W=cdw$v\n  Tt = X%*%W;                    # 3.2.1. 2\n  U = Y%*%C;                    # 3.2.1. 4\n  \n  # Inner relation parameters\n  B_U = solve(t(U)%*%U)%*%t(U)%*%Tt;\n  B_T = solve(t(Tt)%*%Tt)%*%t(Tt)%*%U;\n  \n  #Residuals and R2's\n  E = X_true - Tt%*%t(W) - T_Yosc%*%t(P_Yosc);\n  Ff = Y_true - U%*%t(C) - U_Xosc%*%t(P_Xosc);\n  H_TU = Tt - U%*%B_U;\n  H_UT = U - Tt%*%B_T;\n  Y_hat = Tt%*%B_T%*%t(C);\n  X_hat = U%*%B_U%*%t(W);\n  \n  R2Xcorr = (ssq(Tt%*%t(W))/ssq(X_true))\n  R2Ycorr = (ssq(U%*%t(C))/ssq(Y_true))\n  R2X_YO = (ssq(T_Yosc%*%t(P_Yosc))/ssq(X_true))\n  R2Y_XO = (ssq(U_Xosc%*%t(P_Xosc))/ssq(Y_true))\n  R2Xhat = 1 - (ssq(U%*%B_U%*%t(W) - X_true)/ssq(X_true))\n  R2Yhat = 1 - (ssq(Tt%*%B_T%*%t(C) - Y_true)/ssq(Y_true))\n  R2X = R2Xcorr + R2X_YO\n  R2Y = R2Ycorr + R2Y_XO\n  \n  model=list(\n    Tt=Tt,W.=W,U=U,C.=C,E=E,Ff=Ff,T_Yosc=T_Yosc,P_Yosc.=P_Yosc,W_Yosc=W_Yosc,U_Xosc=U_Xosc,P_Xosc.=P_Xosc,\n    C_Xosc=C_Xosc,B_U=B_U,B_T.=B_T,H_TU=H_TU,H_UT=H_UT,X_hat=X_hat,Y_hat=Y_hat,R2X=R2X,R2Y=R2Y,\n    R2Xcorr=R2Xcorr,R2Ycorr=R2Ycorr,R2X_YO=R2X_YO,R2Y_XO=R2Y_XO,R2Xhat=R2Xhat,R2Yhat=R2Yhat\n  )\n  class(model)='o2m'\n  return(model)\n}\n\n#' Summary of an O2PLS fit\n#' \n#' Until now only variational summary given by the R2's is outputted\n#' \n#' @param fit List. Contains the R2's as produced by \\code{\\link{o2m}}.\n#' @return Matrix with R2 values given in percentage in two decimals.\n#' @examples\n#' summary_o2m(o2m(matrix(-2:2),matrix(-2:2*4),1,0,0))\n#' @export\nsummary_o2m<-function(fit)\n{\n  a=length(fit$W.[1,])\n  Mname=list(c(\"\"),c(\"Comp\",\"R2X\",\"R2Y\",\"R2Xcorr\",'R2Ycorr','R2Xhat',\"R2Yhat\",\"XRatio\",\"YRatio\"))\n  M=matrix(c(a/100,fit$R2X,fit$R2Y,fit$R2Xcorr,fit$R2Ycorr,fit$R2Xhat,fit$R2Yhat,fit$R2Xhat/fit$R2Xcorr,fit$R2Yhat/fit$R2Ycorr),nrow=1,dimnames=Mname)\n  return(round(100*M,2))\n}\n\n#' Root MSE of Prediction\n#' \n#' Calculates the Root MSE of prediction on test data. *Expected* to work in combination with \\code{\\link{loocv}}.\n#' \n#' @param Xtst Numeric vector or matrix.\n#' @param Ytst Numeric vector or matrix.\n#' @param fit \\code{\\link{o2m}} fit (on data without \\code{Xtst} and \\code{Ytst}).\n#' @details This function is the building block for \\code{\\link{loocv}}, as it produced the prediction error for test (left out) data.\n#' @return Mean squares difference between predicted Y and true Y\n#' @export\nrmsep <- function(Xtst,Ytst,fit)\n{\n  n1=n2=T\n  if(!is.matrix(Xtst)){Xtst=t(Xtst);n1=F} # If Xtst is a row-vector\n  if(!is.matrix(Ytst)){Ytst=t(Ytst);n2=F} # If Xtst is a row-vector\n  \n  Yhat = Xtst%*%fit$W.%*%fit$B_T%*%t(fit$C.)\n  Xhat = Ytst%*%fit$C.%*%fit$B_U%*%t(fit$W.)\n  \n  return(mean(c(sqrt(mse(Yhat,Ytst)))))#,sqrt(mse(Xhat,Xtst)))))\n}\n\n#' K fold CV for O2PLS\n#' \n#' For (a grid of) values for \\code{a}, \\code{nx} and \\code{ny}, \\code{loocv} estimates the prediction error using k-fold CV.\n#' \n#' @param X Numeric matrix.\n#' @param Y Numeric matrix.\n#' @param a Vector or integers. Contains the #joint components.\n#' @param a2 Vector or integers. Contains the number of orthogonal components in \\eqn{X}.\n#' @param b2 Vector or integers. Contains the number of orthogonal components in \\eqn{Y}.\n#' @param fitted_model List. O2PLS model fit with \\code{\\link{o2m}}. Is used to calculate the apparent error without recalculating this fit.\n#' @param func Function to fit the O2PLS model with. Only \\code{\\link{o2m}} and \\code{\\link{o2m_stripped}} are supported.\n#' @param app_err Logical. Should the apparent error also be computed?\n#' @param kcv Integer. The value of \\eqn{k}, i.e. the number of folds. Choose \\eqn{N} for LOO-CV.\n#' @details Note that this function can be easily parallelized (on Windows e.g. with the \\code{parallel} package.).\n#' @return List with two numeric vectors:\n#' \\item{CVerr}{Contains the k-fold CV estimated RMSEP}\n#' \\item{Fiterr}{Contains the apparent error}\n#' \n#' @examples\n#' loocv(matrix(c(-2:2)),matrix(c(-2:2*4)),1,0,0,func=o2m,kcv=5)\n#' @export\nloocv <- function(X,Y,a=1:2,a2=1,b2=1,fitted_model=NULL,func=o2m_stripped,app_err=F,kcv)\n  #Input: Data X,Y; model to fit; loop through nr of components; \n  # calculate apparent error?; nr of folds (loo:kcv=N)\n  #Output: several MSE's per chosen nr of component\n{\n  if(!is.null(fitted_model)){app_err=F;warning(\"apparent error calculated with provided fit\")}\n  p=dim(X)[2]\n  # determine type of model\n  type=3#ifelse(deparse(substitute(func))==\"o2m\",3,ifelse(deparse(substitute(func))==\"oplsm\",2,1))\n  \n  N = length(X[,1]);if(N!=length(Y[,1])){stop('N not the same')}\n  mean_err=mean_fit=NA*1:max(length(a),length(a2),length(b2))\n  k=0\n  \n  #blocks contains the begin and endpoints of test indices to use\n  blocks = c(seq(0,N,by=floor(N/kcv)),N)\n  \n  #loop through chosen parameters\n  for(j in a){for(j2 in a2){for(j3 in b2){\n    k=k+1\n    err=NA*1:kcv\n    folds=sample(N)\n    #loop through number of folds\n    for(i in 1:kcv){\n      ii = (blocks[i]+1):(blocks[i+1])\n      if(type==3){pars=list(X=X[-folds[ii],],Y=Y[-folds[ii],],n=j,nx=j2,ny=j3)}\n      if(type==2){pars=list(X=X[-i,],Y=Y[-i,],ncomp=j,n_orth=j2)}\n      if(type==1){pars=list(X=X[-i,],Y=Y[-i,],ncomp=j)}\n      fit=try(do.call(func,pars),silent=T)\n      err[i] = ifelse(class(fit)==\"try-error\",NA,rmsep(X[folds[ii],],Y[folds[ii],],fit))\n    }\n    mean_err[k]=mean(err)\n    #calculate apparent error\n    if(app_err && is.null(fitted_model)){\n      if(type==3){pars2=list(X=X,Y=Y,n=j,nx=j2,ny=j3)}\n#      if(class(fit)=='oplsm'){pars2=list(X=X,Y=Y,ncomp=j,n_orth=j2)}\n#      if(class(fit)=='plsm'){pars2=list(X=X,Y=Y,ncomp=j)}\n      fit2=try(do.call(func,pars2),F)\n      mean_fit[k]=ifelse(class(fit)==\"try-error\",NA,rmsep(X,Y,fit2))\n#      print('1e loop')\n    }\n    if(!is.null(fitted_model))\n    {\n      mean_fit[k]=rmsep(X,Y,fitted_model)\n#      print('2e loop')\n    }\n  }}}\n  return(list(CVerr=mean_err,Fiterr=mean_fit))\n}\n\n#' Gridwise adjusted R2 for O2PLS\n#' \n#' For (a grid of) values for \\code{a}, \\code{nx} and \\code{ny}, \\code{loocv} calculates the R2 of the joint part. Parallel computing is supported on Windows with package \\code{parallel}.\n#' \n#' @param X Numeric matrix.\n#' @param Y Numeric matrix.\n#' @param a Vector or integers. Contains the #joint components.\n#' @param a2 Vector or integers. Contains the number of orthogonal components in \\eqn{X}.\n#' @param b2 Vector or integers. Contains the number of orthogonal components in \\eqn{Y}.\n#' @param func Function to fit the O2PLS model with. Only \\code{\\link{o2m}} and \\code{\\link{o2m_stripped}} are supported.\n#' @param parall Integer. Should a parallel cluster be set up using package \\code{parallel} (Windows)? Best is to leave it to \\code{FALSE}.\n#' @param cl Object of class \"\\code{cluster}\". If parall is \\code{TRUE} and \\code{cl} is not \\code{NULL}, calculations are parallelized over workers in cl.\n#' @details The use of this function is to calculate the R2 of the joint part, while varying the number of orthogonal components. Adding more joint components will increase the R2!\n#' \n#' A parallelized version is built in, use package \\code{parallel} and set \\code{parall=TRUE} to activate this. There should not be already a cluster object with the name \\code{cl}.\n#' In case of some error, don't forget to invoke \\code{stopCluster(cl)} to end the cluster. See Task Manager (Windows) to verify that the workers are spanned/ended.\n#' @return Matrix with two rows:\n#' \\item{adjR2X}{Contains the joint R2 in X}\n#' \\item{adjR2Y}{Contains the joint R2 in Y}\n#' \n#' @examples\n#' adjR2(matrix(c(-2:2)),matrix(c(-2:2*4)),1,0,0,func=o2m)\n#' @export\nadjR2 <- function(X,Y,a=1:2,a2=1,b2=1,func=o2m_stripped,parall=F,cl=NULL)\n  #Input: Data X,Y; model to fit; loop through nr of components; \n  # calculate apparent error?; nr of folds (loo:kcv=N)\n  #Output: several MSE's per chosen nr of component\n{\n  X;Y;\n  cl_was_null=FALSE\n  if(!parall){S_apply=function(cl=NULL,x,fun){sapply(x,fun)}}\n  if(parall&is.null(cl)){\n    cl_was_null=TRUE\n    S_apply=parSapply\n    cl <- makeCluster(rep('localhost', detectCores()),type='SOCK')\n    clusterExport(cl=cl, varlist=c(\"ssq\",'o2m_stripped',\"adjR2\"))\n  }\n  if(parall&!is.null(cl)){S_apply=parSapply}\n  \n  pars1 = merge(merge(data.frame(a = a),data.frame(a2=a2)),data.frame(b2=b2))\n  pars2 = apply(pars1, 1, as.list)\n  N = dim(X)[1]\n  #cl <- makeCluster(rep( 'localhost', detectCores()),type='SOCK')\n  #clusterExport(cl=cl, varlist=c(\"X\",\"Y\",\"N\",\"pars2\",\"ssq\",'o2m'))\n  outp=S_apply(cl,pars2,function(p){\n    fit=func(X,Y,p$a,p$a2,p$b2);\n    RX = 1-ssq(fit$H_UT)/ssq(fit$U)\n    RY = 1-ssq(fit$H_TU)/ssq(fit$Tt)\n    adjRX = RX#1 - (1 - RX)*(N - 1)/(N - p$a - 1)\n    adjRY = RY#1 - (1 - RY)*(N - 1)/(N - p$a - 1)\n    return(list(adjR2X = adjRX, adjR2Y = adjRY))\n  })\n  if(parall&cl_was_null==TRUE){stopCluster(cl)}\n  return(outp)\n}\n\n#' Norm of a vector or columns of a matrix\n#' \n#' @param x Numeric vector or matrix.\n#' @return (columnwise) Euclidian norm of \\eqn{x}\n#' @export\nvnorm <- function(x)\n  #Input: matrix x\n  #Output: 2-norm of X per column ( ssq(X) = sum(vnorm(X)) )\n{\n  x = as.matrix(x)\n  return(sqrt(apply(x^2,2,sum)))\n}\n#' Perform O2-PLS with two-way orthogonal corrections\n#' \n#' NOTE THAT THIS FUNCTION DOES NOT CENTER NOR SCALES THE MATRICES! Any normalization you will have to do yourself. It is best practice to at least center the variables though.\n#' A stripped version of O2PLS\n#' \n#' @param X Numeric matrix. Other types will be coerced to matrix with \\code{as.matrix} (if this is possible)\n#' @param Y Numeric matrix. Other types will be coerced to matrix with \\code{as.matrix} (if this is possible)\n#' @param n Integer. Number of joint PLS components. Must be positive!\n#' @param nx Integer. Number of orthogonal components in \\eqn{X}. Negative values are interpreted as 0\n#' @param ny Integer. Number of orthogonal components in \\eqn{Y}. Negative values are interpreted as 0\n#' \n#' @return A list containing\n#'    \\item{Tt}{Joint \\eqn{X} scores}\n#'    \\item{W.}{Joint \\eqn{X} loadings}\n#'    \\item{U}{Joint \\eqn{Y} scores}\n#'    \\item{C.}{Joint \\eqn{Y} loadings}\n#'    \\item{P_Yosc.}{Orthogonal \\eqn{X} loadings}\n#'    \\item{P_Xosc.}{Orthogonal \\eqn{Y} loadings}\n#'    \\item{B_U}{Regression coefficient in \\code{Tt} ~ \\code{U}}\n#'    \\item{B_T.}{Regression coefficient in \\code{U} ~ \\code{Tt}}\n#'    \\item{H_TU}{Residuals in \\code{Tt} in \\code{Tt} ~ \\code{U}}\n#'    \\item{H_UT}{Residuals in \\code{U} in \\code{U} ~ \\code{Tt}}\n#'    \n#'    @details If both \\code{nx} and \\code{ny} are zero, \\code{o2m} is equivalent to PLS2 with orthonormal loadings.\n#'    This is a stripped implementation of O2PLS, using \\code{\\link{svd}}. For data analysis purposes, consider using \\code{\\link{o2m}}.\n#'    \n#'    @seealso \\code{\\link{ssq}}, \\code{\\link{o2m}}, \\code{\\link{loocv}}, \\code{\\link{adjR2}}\n#' @export\no2m_stripped<-function(X,Y,n,nx,ny)\n{\n  X = as.matrix(X)\n  Y = as.matrix(Y)\n  if(n<=0){stop(\"#joint components must be >0\")}\n  \n  X_true = X\n  Y_true = Y\n  \n  N=dim(X)[1]\n  p=dim(X)[2]; q=dim(Y)[2]\n  \n  T_Yosc = U_Xosc = matrix(NA,N,1)\n  P_Yosc = W_Yosc = matrix(NA,p,1)\n  P_Xosc = C_Xosc = matrix(NA,q,1)\n  \n  if(nx+ny>0){\n    n2=n+max(nx,ny)\n    \n    cdw = svd(t(Y)%*%X,nu=n2,nv=n2); # 3.2.1. 1\n    C=cdw$u;W=cdw$v\n    rm(cdw)\n    Tt = X%*%W;                    # 3.2.1. 2\n    \n    if(nx > 0){\n      # 3.2.1. 3\n      E_XY = X \n      E_XY = E_XY - Tt%*%t(W);\n      \n      udv = svd(t(E_XY)%*%Tt,nu=nx,nv=0);\n      rm(E_XY)\n      W_Yosc = udv$u \n      T_Yosc = X%*%W_Yosc;\n      P_Yosc = t(solve(t(T_Yosc)%*%T_Yosc)%*%t(T_Yosc)%*%X);\n      X = X - T_Yosc%*%t(P_Yosc);\n      \n      # Update T again (since X has changed)\n      Tt = X%*%W;\n    }\n    \n    U = Y%*%C;                   # 3.2.1. 4\n    \n    if(ny > 0){\n      # 3.2.1. 5\n      F_XY = Y \n      F_XY = F_XY - U%*%t(C);\n      \n      udv = svd(t(F_XY)%*%U,nu=ny,nv=0);\n      rm(F_XY)\n      C_Xosc = udv$u ; s = udv$d \n      U_Xosc = Y%*%C_Xosc;\n      P_Xosc = t(solve(t(U_Xosc)%*%U_Xosc)%*%t(U_Xosc)%*%Y);\n      Y = Y - U_Xosc%*%t(P_Xosc);\n      \n      # Update U again (since Y has changed) \n      U = Y%*%C;\n    }\n  }\n  \n  # repeat steps 1, 2, and 4 before step 6\n  cdw = svd(t(Y)%*%X,nu=n,nv=n);    # 3.2.1. 1\n  C=cdw$u;W=cdw$v\n  Tt = X%*%W;                    # 3.2.1. 2\n  U = Y%*%C;                    # 3.2.1. 4\n  \n  # 3.2.1. 6\n  B_U = solve(t(U)%*%U)%*%t(U)%*%Tt;\n  B_T = solve(t(Tt)%*%Tt)%*%t(Tt)%*%U;\n  H_TU = Tt - U%*%B_U;\n  H_UT = U - Tt%*%B_T;\n  \n  model=list(Tt=Tt,U=U,W.=W,C.=C,P_Yosc.=P_Yosc,P_Xosc.=P_Xosc,B_T.=B_T,B_U=B_U,H_TU=H_TU,H_UT=H_UT)\n  class(model)='o2m'\n  return(model)\n}\n\n#' Symmetrized root MSE of Prediction\n#' \n#' Calculates the symmetrized root MSE of prediction on test data. *Expected* to work in combination with \\code{\\link{loocv}}.\n#' \n#' @param Xtst Numeric vector or matrix.\n#' @param Ytst Numeric vector or matrix.\n#' @param fit \\code{\\link{o2m}} fit (on data without \\code{Xtst} and \\code{Ytst}).\n#' @details This function is the building block for \\code{\\link{loocv}}, as it produced the prediction error for test (left out) data.\n#' \n#' This is a symmetrized version of \\code{\\link{rmsep}}, and is used by \\code{\\link{loocv}}. The predicion error of both \\code{Xtst} and \\code{Ytst} are calculated and summed.\n#' Whether this is a good idea depends: If \\eqn{X} and \\eqn{Y} have similar meanings (LC-MS versus MALDI) this is a good thing to do. If the two matrices do not have similar meanings,\n#' (Metabolomics versus Transcriptomics) then you may want to not sum up the two prediction errors or include weights in the sum.\n#' @return Mean squares difference between predicted Y and true Y\n#' @export\nrmsep_combi <- function(Xtst,Ytst,fit)\n  #Input: test matrices (now: row i of data X,Y); used model\n  #Output: MSE of Yhat from model, wrt Ytest\n{\n  n1=n2=T\n  if(!is.matrix(Xtst)){Xtst=t(Xtst);n1=F} # If Xtst is a row-vector\n  if(!is.matrix(Ytst)){Ytst=t(Ytst);n2=F} # If Xtst is a row-vector\n  \n  if(class(fit)=='plsm')\n    # PLS fit is quickly done\n  {\n    Yhat=cbind(1,Xtst)%*%fit$ori\n  }\n  \n  if(class(fit)=='oplsm')\n    # OPLS corrects Xtst\n  {\n    if(n1){Xtst=oscr(Xtst,Ytst,n_orth=n_orth)$Xcorr}\n    Yhat=cbind(1,Xtst)%*%fit$ori\n  }\n  \n  if(class(fit)=='o2m')\n    # O2PLS we should correct both Xtst and Ytst?\n  {\n    if(n1)\n    {\n      #To=Xtst%*%fit$W_Yosc\n      #Po=t(solve(t(To)%*%To)%*%t(To)%*%Xtst)\n      Xtst=Xtst# - tcrossprod(To,Po)\n    }\n    Yhat = Xtst%*%fit$W.%*%fit$B_T%*%t(fit$C.)\n    Xhat = Ytst%*%fit$C.%*%fit$B_U%*%t(fit$W.)\n  }\n  return( sqrt(mse(Yhat,Ytst)) + sqrt(mse(Xhat,Xtst)) )\n}\n\n#' K-fold CV based on symmetrized prediction error\n#' \n#' The prediction error of both \\code{X~Xhat} and \\code{Y~Yhat} are summed. This provides a symmetrized version of \\code{\\link{loocv}}.\n#' @param X Numeric matrix.\n#' @param Y Numeric matrix.\n#' @param a Vector or integers. Contains the #joint components.\n#' @param a2 Vector or integers. Contains the number of orthogonal components in \\eqn{X}.\n#' @param b2 Vector or integers. Contains the number of orthogonal components in \\eqn{Y}.\n#' @param fitted_model List. O2PLS model fit with \\code{\\link{o2m}}. Is used to calculate the apparent error without recalculating this fit.\n#' @param func Function to fit the O2PLS model with. Only \\code{\\link{o2m}} and \\code{\\link{o2m_stripped}} are supported.\n#' @param app_err Logical. Should the apparent error also be computed?\n#' @param kcv Integer. The value of \\eqn{k}, i.e. the number of folds. Choose \\eqn{N} for LOO-CV.\n#' @details Note that this function can be easily parallelized (on Windows e.g. with the \\code{parallel} package.).\n#' @return List with two numeric vectors:\n#' \\item{CVerr}{Contains the k-fold CV estimated RMSEP}\n#' \\item{Fiterr}{Contains the apparent error}\n#' \n#' @examples\n#' loocv_combi(matrix(c(-2:2)),matrix(c(-2:2*4)),1,0,0,func=o2m,kcv=5)\n#' @export\nloocv_combi <- function(X,Y,a=1:2,a2=1,b2=1,fitted_model=NULL,func=o2m_stripped,app_err=F,kcv)\n  #Input: Data X,Y; model to fit; loop through nr of components; \n  # calculate apparent error?; nr of folds (loo:kcv=N)\n  #Output: several MSE's per chosen nr of component\n{\n  if(!is.null(fitted_model)){app_err=F;warning(\"apparent error calculated with provided fit\")}\n  p=dim(X)[2]\n  # determine type of model\n  type=3#ifelse(deparse(substitute(func))==\"o2m\",3,ifelse(deparse(substitute(func))==\"oplsm\",2,1))\n  \n  N = length(X[,1]);if(N!=length(Y[,1])){stop('N not the same')}\n  mean_err=mean_fit=NA*1:max(length(a),length(a2),length(b2))\n  k=0\n  \n  #blocks contains the begin and endpoints of test indices to use\n  blocks = c(seq(0,N,by=floor(N/kcv)),N)\n  \n  #loop through chosen parameters\n  for(j in a){for(j2 in a2){for(j3 in b2){\n    k=k+1\n    err=NA*1:kcv\n    folds=sample(N)\n    #loop through number of folds\n    for(i in 1:kcv){\n      ii = (blocks[i]+1):(blocks[i+1])\n      if(type==3){pars=list(X=X[-folds[ii],],Y=Y[-folds[ii],],n=j,nx=j2,ny=j3)}\n      if(type==2){pars=list(X=X[-i,],Y=Y[-i,],ncomp=j,n_orth=j2)}\n      if(type==1){pars=list(X=X[-i,],Y=Y[-i,],ncomp=j)}\n      fit=try(do.call(func,pars),silent=T)\n      err[i] = ifelse(class(fit)==\"try-error\",NA,rmsep_combi(X[folds[ii],],Y[folds[ii],],fit))\n    }\n    mean_err[k]=mean(err)\n    #calculate apparent error\n    if(app_err && is.null(fitted_model)){\n      if(class(fit)=='o2m'){pars2=list(X=X,Y=Y,n=j,nx=j2,ny=j3)}\n      if(class(fit)=='oplsm'){pars2=list(X=X,Y=Y,ncomp=j,n_orth=j2)}\n      if(class(fit)=='plsm'){pars2=list(X=X,Y=Y,ncomp=j)}\n      fit2=try(do.call(func,pars2),T)\n      mean_fit[k]=ifelse(class(fit)==\"try-error\",NA,rmsep_combi(X,Y,fit2))\n      print('1e loop')\n    }\n    if(!is.null(fitted_model))\n    {\n      mean_fit[k]=rmsep_combi(X,Y,fitted_model)\n      print('2e loop')\n    }\n  }}}\n  return(list(CVerr=mean_err,Fiterr=mean_fit))\n}",
    "created" : 1430640440388.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2686093324",
    "id" : "DD03F92D",
    "lastKnownWriteTime" : 1430731825,
    "path" : "C:/Users/selbouhaddani/GitHub/O2PLS/R/O2PLS.R",
    "project_path" : "R/O2PLS.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}